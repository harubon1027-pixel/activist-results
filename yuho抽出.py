import os
import pandas as pd
import requests, zipfile, io
from datetime import datetime, timedelta

API_KEY = "b3179bcab14b4053a5928dce030612f3"
BASE_URL = "https://api.edinet-fsa.go.jp/api/v2"
OUTPUT_DIR = "yuho"

os.makedirs(OUTPUT_DIR, exist_ok=True)

# ===== å¯¾è±¡æ§˜å¼ã‚³ãƒ¼ãƒ‰ï¼ˆæœ‰å ±/åŠæœŸ/å››åŠæœŸï¼‰ =====
YUHO_ORD_FORM = {
    ("010", "030000"), # æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸
    ("010", "100000"), # åŠæœŸå ±å‘Šæ›¸
}

def is_target_report(doc: dict, edinet_codes: set) -> bool:
    ord_code = str(doc.get("ordinanceCode") or "").zfill(3)
    form_code = str(doc.get("formCode") or "").zfill(6)
    edinet_code = doc.get("edinetCode")
    return edinet_code in edinet_codes and (ord_code, form_code) in YUHO_ORD_FORM

def get_documents_list(date_str):
    url = f"{BASE_URL}/documents.json"
    params = {"date": date_str, "type": 2, "Subscription-Key": API_KEY}
    res = requests.get(url, params=params, timeout=30)
    if res.status_code != 200:
        print(f"âŒ æ›¸é¡ä¸€è¦§å–å¾—å¤±æ•—: {date_str}, HTTP {res.status_code}")
        return []
    return res.json().get("results", [])

def download_xbrl(doc_id):
    try:
        url = f"{BASE_URL}/documents/{doc_id}"
        params = {"type": 1, "Subscription-Key": API_KEY}
        res = requests.get(url, params=params, timeout=60)
        res.raise_for_status()

        save_path = os.path.join(OUTPUT_DIR, f"{doc_id}.zip")
        with open(save_path, "wb") as f:
            f.write(res.content)

        with zipfile.ZipFile(io.BytesIO(res.content)) as z:
            z.extractall(os.path.join(OUTPUT_DIR, doc_id))

        print(f"âœ… {doc_id}.zip ä¿å­˜ï¼†è§£å‡å®Œäº†")
    except Exception as e:
        print(f"âŒ {doc_id} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")

def main():
    # 1. ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ã‚¹ãƒˆéŠ˜æŸ„ä¸€è¦§
    activist_path = os.path.join("docs", "ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ã‚¹ãƒˆéŠ˜æŸ„ä¸€è¦§.xlsx")
    activist_df = pd.read_excel(activist_path)
    target_sec_codes = set(str(c).zfill(4) + "0" for c in activist_df["è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰"].dropna().unique())

    # 2. docs/EdinetcodeDlInfo.csv ã‚’èª­ã¿è¾¼ã‚€
    code_df = pd.read_csv(os.path.join("docs", "EdinetcodeDlInfo.csv"), encoding="cp932", skiprows=1)

    # 3. åˆ—åã§æŒ‡å®š
    edinet_col = code_df["ï¼¥ï¼¤ï¼©ï¼®ï¼¥ï¼´ã‚³ãƒ¼ãƒ‰"]
    sec_col = code_df["è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰"].astype(str).str.strip()

    # 4. ãƒãƒƒãƒãƒ³ã‚°
    edinet_codes = set(edinet_col[sec_col.isin(target_sec_codes)].tolist())
    print(f"ğŸ¯ å¯¾è±¡EDINETã‚³ãƒ¼ãƒ‰: {len(edinet_codes)}ä»¶")

    # 5. ç›´è¿‘1å¹´é–“ã®æå‡ºæ›¸é¡ã‚’æ¢ç´¢
    today = datetime.now().date()
    days = 365
    for i in range(days):
        date_str = (today - timedelta(days=i)).strftime("%Y-%m-%d")
        docs = get_documents_list(date_str)
        for doc in docs:
            if is_target_report(doc, edinet_codes):
                doc_id = doc["docID"]
                desc = doc.get("docDescription") or ""
                print(f"ğŸ“Œ Hit: {doc_id}, {desc}")
                download_xbrl(doc_id)

if __name__ == "__main__":
    main()
